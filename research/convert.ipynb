{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scikit-learn version 1.2.0 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n",
      "Torch version 2.0.0.dev20230104 has not been tested with coremltools. You may run into unexpected errors. Torch 1.12.1 is the most recent version that has been tested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchlibrosa\n",
    "import numpy as np\n",
    "import soundfile\n",
    "import os\n",
    "import coremltools as ct\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import librosa\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "\n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveToSpectrogram(nn.Module):\n",
    "\n",
    "    def __init__( self, n_fft, hop_length, center=False ):\n",
    "        super(WaveToSpectrogram, self).__init__()\n",
    "\n",
    "        self.spec_extractor = torchlibrosa.stft.Spectrogram(\n",
    "            n_fft=n_fft,\n",
    "            hop_length=hop_length,\n",
    "            center=center,\n",
    "        )\n",
    "\n",
    "    def forward( self, x ):\n",
    "        return self.spec_extractor( x )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hugo/opt/anaconda3/envs/audio/lib/python3.8/site-packages/torchlibrosa/stft.py:193: FutureWarning: Pass size=1024 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  fft_window = librosa.util.pad_center(fft_window, n_fft)\n",
      "/Users/hugo/opt/anaconda3/envs/audio/lib/python3.8/site-packages/torch/serialization.py:359: UserWarning: Couldn't retrieve source code for container of type WaveToSpectrogram. It won't be checked for correctness upon loading.\n",
      "  warnings.warn(\"Couldn't retrieve source code for container of \"\n"
     ]
    }
   ],
   "source": [
    "model = WaveToSpectrogram( n_fft=1024, hop_length=512 )\n",
    "torch.save(model, 'Hello.pt')\n",
    "\n",
    "waveform, samplerate = soundfile.read( 'bonjour.wav' )\n",
    "sample_input = waveform[:32000].astype( dtype=np.float32 )\n",
    "\n",
    "# instantiate model and export it\n",
    "model = WaveToSpectrogram( n_fft=1024, hop_length=512 )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to Onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    return torch.device(\"cpu\")\n",
    "device=get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'history/Cnn10_lr_0.005_ep_100_bs_32_valoss_1.5_acc_0.94_recall_0.89_precision_0.89'\n",
    "#model_path = 'history/MobileNetV1_lr_0.005_ep_100_bs_32_valoss_1.5773910284042358_acc_0.82_recall_0.82_precision_0.82'\n",
    "waveform, samplerate = soundfile.read( '../urbansound8k/audio/fold1/101415-3-0-2.wav' )\n",
    "sample_input = waveform[:192000].astype( dtype=np.float32).reshape((1, 192000))\n",
    "\n",
    "def export_torch_onnx(model, sample_input, filename_onnx):\n",
    "    torch.onnx.export(\n",
    "            model,\n",
    "            torch.from_numpy( sample_input).to(device),\n",
    "            filename_onnx,\n",
    "            verbose = True,\n",
    "            )\n",
    "model = torch.load(os.path.join(model_path, 'model.pt'))\n",
    "export_torch_onnx(model, sample_input, os.path.join(model_path, 'model_test.onnx'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX to Coreml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlmodel = onnx_coreml.convert(model = 'wave_to_spectrogram_model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mlmodel = onnx_coreml.convert(\n",
    "    model = 'wave_to_spectrogram_model.onnx',\n",
    "    minimum_ios_deployment_target='13',\n",
    ")\n",
    "mlmodel.save(os.path.join(model_path, 'model.mlmodel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx_coreml\n",
    "import coremltools\n",
    "model_path = 'history/Cnn10_lr_0.005_ep_100_bs_32_valoss_1.5_acc_0.94_recall_0.89_precision_0.89'\n",
    "\n",
    "mlmodel = onnx_coreml.convert(\n",
    "    model = os.path.join(model_path, 'model.onnx'),\n",
    "    mode = 'classifier',\n",
    "    minimum_ios_deployment_target='13',\n",
    "    class_labels='labels.txt',\n",
    ")\n",
    "mlmodel.save(os.path.join(model_path, 'model.mlmodel'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch to CoreML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_pytorch_to_coreml(model, example_input: torch.Tensor, output_filename='model.mlpackage') -> None:\n",
    "    model.eval()\n",
    "    # Trace the model with exemple_input.\n",
    "    traced_model = torch.jit.trace(model, example_input, strict=False)\n",
    "    out = traced_model(example_input)\n",
    "    # Using image_input in the inputs parameter:\n",
    "    # Convert to Core ML program using the Unified Conversion API.\n",
    "    labels = [\"air_conditioner\",\n",
    "            \"car_horn\",\n",
    "            \"children_playing\",\n",
    "            \"dog_bark\",\n",
    "            \"drilling\",\n",
    "            \"engine_idling\",\n",
    "            \"gun_shot\",\n",
    "            \"jackhammer\",\n",
    "            \"siren\",\n",
    "            \"street_music\"]\n",
    "    classifier_config_ = ct.ClassifierConfig(labels)\n",
    "\n",
    "    traced_model.eval()\n",
    "    model = ct.convert(\n",
    "        traced_model,\n",
    "        minimum_deployment_target=ct.target.iOS13,\n",
    "        convert_to='neuralnetwork',\n",
    "        compute_units=ct.ComputeUnit.ALL,\n",
    "        classifier_config=classifier_config_,\n",
    "        inputs=[ct.TensorType(shape=example_input.shape)]\n",
    "    )\n",
    "    model.save(output_filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mobiletnetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'history/Cnn10_lr_0.005_ep_100_bs_32_valoss_1.5_acc_0.94_recall_0.89_precision_0.89'\n",
    "#model_path = 'history/MobileNetV1_lr_0.005_ep_100_bs_32_valoss_1.5773910284042358_acc_0.82_recall_0.82_precision_0.82'\n",
    "waveform, samplerate = soundfile.read( '../urbansound8k/audio/fold1/101415-3-0-2.wav' )\n",
    "sample_input = waveform[:192000].astype( dtype=np.float32).reshape((1, 192000))\n",
    "\n",
    "model = torch.load(os.path.join(model_path, 'model.pt'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 384/385 [00:00<00:00, 2069.73 ops/s]\n",
      "Running MIL Common passes:   0%|          | 0/33 [00:00<?, ? passes/s]/Users/hugo/opt/anaconda3/envs/coremltools3.8/lib/python3.8/site-packages/coremltools/converters/mil/mil/passes/name_sanitization_utils.py:101: UserWarning: Input, 'x.1', of the source model, has been renamed to 'x_1' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 109.90 passes/s]\n",
      "Running MIL FP16ComputePrecision pass: 100%|██████████| 1/1 [00:00<00:00,  2.34 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00,  9.42 passes/s]\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained version of MobileNetV2\n",
    "torch_model = torchvision.models.mobilenet_v2(pretrained=True)\n",
    "# Set the model in evaluation mode.\n",
    "torch_model.eval()\n",
    "\n",
    "# Trace the model with random data.\n",
    "example_input = torch.rand(1, 3, 224, 224) \n",
    "traced_model = torch.jit.trace(torch_model, example_input)\n",
    "out = traced_model(example_input)\n",
    "\n",
    "# Using image_input in the inputs parameter:\n",
    "# Convert to Core ML program using the Unified Conversion API.\n",
    "\n",
    "traced_model.eval()\n",
    "model = ct.convert(\n",
    "    traced_model,\n",
    "    convert_to=\"mlprogram\",\n",
    "    inputs=[ct.TensorType(shape=example_input.shape)]\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple layer module we'll reuse in our network.\n",
    "class Layer(nn.Module):\n",
    "    def __init__(self, dims):\n",
    "        super(Layer, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(*dims)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, (2, 2))\n",
    "        return x\n",
    "\n",
    "# A simple network consisting of several base layers.\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.layer1 = Layer((3, 6, 3))\n",
    "        self.layer2 = Layer((6, 16, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "model = SimpleNet()  # Instantiate the network.\n",
    "example = torch.rand(1, 3, 224, 224)  # Example input, needed by jit tracer.\n",
    "traced = torch.jit.trace(model, example)  # Generate TorchScript by tracing.\n",
    "scripted = torch.jit.script(model)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Pytorch with coreml \n",
    "* python3.8\n",
    "* pip3 install --pre torch torchvision torchaudio -f https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html\n",
    "* pip3 install coremltools==6.1 protobuf==3.20.1\n",
    "* pip3 install \"numpy<1.24\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mobilenetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hugo/opt/anaconda3/envs/coremltools3.8/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/hugo/opt/anaconda3/envs/coremltools3.8/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 384/385 [00:00<00:00, 2018.19 ops/s]\n",
      "Running MIL Common passes:   0%|          | 0/33 [00:00<?, ? passes/s]/Users/hugo/opt/anaconda3/envs/coremltools3.8/lib/python3.8/site-packages/coremltools/converters/mil/mil/passes/name_sanitization_utils.py:129: UserWarning: Output, '647', of the source model, has been renamed to 'var_647' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 108.20 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 147.11 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 495/495 [00:00<00:00, 1421.09 ops/s]\n",
      "[W backend_detail.cpp:393] Warning: Backend [coreml] is not available. Execution of this Module is still possible by saving and loading on a device where the backend is available. (function codegen_backend_module)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input {\n",
      "  name: \"input_0\"\n",
      "  type {\n",
      "    multiArrayType {\n",
      "      shape: 1\n",
      "      shape: 3\n",
      "      shape: 224\n",
      "      shape: 224\n",
      "      dataType: FLOAT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "output {\n",
      "  name: \"var_647\"\n",
      "  type {\n",
      "    multiArrayType {\n",
      "      dataType: FLOAT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "metadata {\n",
      "  userDefined {\n",
      "    key: \"com.github.apple.coremltools.source\"\n",
      "    value: \"torch==2.0.0.dev20230104\"\n",
      "  }\n",
      "  userDefined {\n",
      "    key: \"com.github.apple.coremltools.version\"\n",
      "    value: \"5.0b5\"\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch.backends._coreml.preprocess import (\n",
    "    CompileSpec,\n",
    "    TensorSpec,\n",
    "    CoreMLComputeUnit,\n",
    ")\n",
    "\n",
    "def mobilenetv2_spec():\n",
    "    return {\n",
    "        \"forward\": CompileSpec(\n",
    "            inputs=(\n",
    "                TensorSpec(\n",
    "                    shape=[1, 3, 224, 224],\n",
    "                ),\n",
    "            ),\n",
    "            outputs=(\n",
    "                TensorSpec(\n",
    "                    shape=[1, 1000],\n",
    "                ),\n",
    "            ),\n",
    "            backend=CoreMLComputeUnit.ALL,\n",
    "            allow_low_precision=True,\n",
    "        ),\n",
    "    }\n",
    "\n",
    "\n",
    "model = torchvision.models.mobilenet_v2(pretrained=True)\n",
    "model.eval()\n",
    "example = torch.rand(1, 3, 224, 224)\n",
    "model = torch.jit.trace(model, example)\n",
    "compile_spec = mobilenetv2_spec()\n",
    "mlmodel = torch._C._jit_to_backend(\"coreml\", model, compile_spec)\n",
    "mlmodel._save_for_lite_interpreter(\"./mobilenetv2_coreml.ptl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cnn10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cnn10(\n",
       "  (spectrogram_extractor): Spectrogram(\n",
       "    (stft): STFT(\n",
       "      (conv_real): Conv1d(1, 513, kernel_size=(1024,), stride=(320,), bias=False)\n",
       "      (conv_imag): Conv1d(1, 513, kernel_size=(1024,), stride=(320,), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (logmel_extractor): LogmelFilterBank()\n",
       "  (spec_augmenter): SpecAugmentation(\n",
       "    (time_dropper): DropStripes()\n",
       "    (freq_dropper): DropStripes()\n",
       "  )\n",
       "  (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_block1): ConvBlock(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_block2): ConvBlock(\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_block3): ConvBlock(\n",
       "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_block4): ConvBlock(\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc_audioset): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(\"history/Cnn10_lr_0.005_ep_100_bs_64_valoss_1.49_acc_0.95_recall_0.96_precision_0.96/model.pt\", map_location=torch.device('cpu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.1153e-10, 2.8249e-12, 8.2549e-10, 1.0000e+00, 6.6232e-07, 5.0575e-13,\n",
       "         9.9407e-06, 5.6270e-06, 8.9517e-13, 5.1365e-09]],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobilenetv2(input_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hugo/opt/anaconda3/envs/coremltools3.8/lib/python3.8/site-packages/torchlibrosa/stft.py:193: FutureWarning: Pass size=1024 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  fft_window = librosa.util.pad_center(fft_window, n_fft)\n",
      "/Users/hugo/opt/anaconda3/envs/coremltools3.8/lib/python3.8/site-packages/librosa/util/decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Spectrogram: 1-1                       --\n",
      "|    └─STFT: 2-1                         --\n",
      "|    |    └─Conv1d: 3-1                  (525,312)\n",
      "|    |    └─Conv1d: 3-2                  (525,312)\n",
      "├─LogmelFilterBank: 1-2                  (32,832)\n",
      "├─SpecAugmentation: 1-3                  --\n",
      "|    └─DropStripes: 2-2                  --\n",
      "|    └─DropStripes: 2-3                  --\n",
      "├─BatchNorm2d: 1-4                       128\n",
      "├─Sequential: 1-5                        --\n",
      "|    └─Sequential: 2-4                   --\n",
      "|    |    └─Conv2d: 3-3                  288\n",
      "|    |    └─AvgPool2d: 3-4               --\n",
      "|    |    └─BatchNorm2d: 3-5             64\n",
      "|    |    └─ReLU: 3-6                    --\n",
      "|    └─Sequential: 2-5                   --\n",
      "|    |    └─Conv2d: 3-7                  288\n",
      "|    |    └─AvgPool2d: 3-8               --\n",
      "|    |    └─BatchNorm2d: 3-9             64\n",
      "|    |    └─ReLU: 3-10                   --\n",
      "|    |    └─Conv2d: 3-11                 2,048\n",
      "|    |    └─BatchNorm2d: 3-12            128\n",
      "|    |    └─ReLU: 3-13                   --\n",
      "|    └─Sequential: 2-6                   --\n",
      "|    |    └─Conv2d: 3-14                 576\n",
      "|    |    └─AvgPool2d: 3-15              --\n",
      "|    |    └─BatchNorm2d: 3-16            128\n",
      "|    |    └─ReLU: 3-17                   --\n",
      "|    |    └─Conv2d: 3-18                 8,192\n",
      "|    |    └─BatchNorm2d: 3-19            256\n",
      "|    |    └─ReLU: 3-20                   --\n",
      "|    └─Sequential: 2-7                   --\n",
      "|    |    └─Conv2d: 3-21                 1,152\n",
      "|    |    └─AvgPool2d: 3-22              --\n",
      "|    |    └─BatchNorm2d: 3-23            256\n",
      "|    |    └─ReLU: 3-24                   --\n",
      "|    |    └─Conv2d: 3-25                 16,384\n",
      "|    |    └─BatchNorm2d: 3-26            256\n",
      "|    |    └─ReLU: 3-27                   --\n",
      "|    └─Sequential: 2-8                   --\n",
      "|    |    └─Conv2d: 3-28                 1,152\n",
      "|    |    └─AvgPool2d: 3-29              --\n",
      "|    |    └─BatchNorm2d: 3-30            256\n",
      "|    |    └─ReLU: 3-31                   --\n",
      "|    |    └─Conv2d: 3-32                 32,768\n",
      "|    |    └─BatchNorm2d: 3-33            512\n",
      "|    |    └─ReLU: 3-34                   --\n",
      "|    └─Sequential: 2-9                   --\n",
      "|    |    └─Conv2d: 3-35                 2,304\n",
      "|    |    └─AvgPool2d: 3-36              --\n",
      "|    |    └─BatchNorm2d: 3-37            512\n",
      "|    |    └─ReLU: 3-38                   --\n",
      "|    |    └─Conv2d: 3-39                 65,536\n",
      "|    |    └─BatchNorm2d: 3-40            512\n",
      "|    |    └─ReLU: 3-41                   --\n",
      "|    └─Sequential: 2-10                  --\n",
      "|    |    └─Conv2d: 3-42                 2,304\n",
      "|    |    └─AvgPool2d: 3-43              --\n",
      "|    |    └─BatchNorm2d: 3-44            512\n",
      "|    |    └─ReLU: 3-45                   --\n",
      "|    |    └─Conv2d: 3-46                 131,072\n",
      "|    |    └─BatchNorm2d: 3-47            1,024\n",
      "|    |    └─ReLU: 3-48                   --\n",
      "|    └─Sequential: 2-11                  --\n",
      "|    |    └─Conv2d: 3-49                 4,608\n",
      "|    |    └─AvgPool2d: 3-50              --\n",
      "|    |    └─BatchNorm2d: 3-51            1,024\n",
      "|    |    └─ReLU: 3-52                   --\n",
      "|    |    └─Conv2d: 3-53                 262,144\n",
      "|    |    └─BatchNorm2d: 3-54            1,024\n",
      "|    |    └─ReLU: 3-55                   --\n",
      "|    └─Sequential: 2-12                  --\n",
      "|    |    └─Conv2d: 3-56                 4,608\n",
      "|    |    └─AvgPool2d: 3-57              --\n",
      "|    |    └─BatchNorm2d: 3-58            1,024\n",
      "|    |    └─ReLU: 3-59                   --\n",
      "|    |    └─Conv2d: 3-60                 262,144\n",
      "|    |    └─BatchNorm2d: 3-61            1,024\n",
      "|    |    └─ReLU: 3-62                   --\n",
      "|    └─Sequential: 2-13                  --\n",
      "|    |    └─Conv2d: 3-63                 4,608\n",
      "|    |    └─AvgPool2d: 3-64              --\n",
      "|    |    └─BatchNorm2d: 3-65            1,024\n",
      "|    |    └─ReLU: 3-66                   --\n",
      "|    |    └─Conv2d: 3-67                 262,144\n",
      "|    |    └─BatchNorm2d: 3-68            1,024\n",
      "|    |    └─ReLU: 3-69                   --\n",
      "|    └─Sequential: 2-14                  --\n",
      "|    |    └─Conv2d: 3-70                 4,608\n",
      "|    |    └─AvgPool2d: 3-71              --\n",
      "|    |    └─BatchNorm2d: 3-72            1,024\n",
      "|    |    └─ReLU: 3-73                   --\n",
      "|    |    └─Conv2d: 3-74                 262,144\n",
      "|    |    └─BatchNorm2d: 3-75            1,024\n",
      "|    |    └─ReLU: 3-76                   --\n",
      "|    └─Sequential: 2-15                  --\n",
      "|    |    └─Conv2d: 3-77                 4,608\n",
      "|    |    └─AvgPool2d: 3-78              --\n",
      "|    |    └─BatchNorm2d: 3-79            1,024\n",
      "|    |    └─ReLU: 3-80                   --\n",
      "|    |    └─Conv2d: 3-81                 262,144\n",
      "|    |    └─BatchNorm2d: 3-82            1,024\n",
      "|    |    └─ReLU: 3-83                   --\n",
      "|    └─Sequential: 2-16                  --\n",
      "|    |    └─Conv2d: 3-84                 4,608\n",
      "|    |    └─AvgPool2d: 3-85              --\n",
      "|    |    └─BatchNorm2d: 3-86            1,024\n",
      "|    |    └─ReLU: 3-87                   --\n",
      "|    |    └─Conv2d: 3-88                 524,288\n",
      "|    |    └─BatchNorm2d: 3-89            2,048\n",
      "|    |    └─ReLU: 3-90                   --\n",
      "|    └─Sequential: 2-17                  --\n",
      "|    |    └─Conv2d: 3-91                 9,216\n",
      "|    |    └─AvgPool2d: 3-92              --\n",
      "|    |    └─BatchNorm2d: 3-93            2,048\n",
      "|    |    └─ReLU: 3-94                   --\n",
      "|    |    └─Conv2d: 3-95                 1,048,576\n",
      "|    |    └─BatchNorm2d: 3-96            2,048\n",
      "|    |    └─ReLU: 3-97                   --\n",
      "├─Linear: 1-6                            1,049,600\n",
      "├─Linear: 1-7                            10,250\n",
      "=================================================================\n",
      "Total params: 5,349,834\n",
      "Trainable params: 4,266,378\n",
      "Non-trainable params: 1,083,456\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─Spectrogram: 1-1                       --\n",
       "|    └─STFT: 2-1                         --\n",
       "|    |    └─Conv1d: 3-1                  (525,312)\n",
       "|    |    └─Conv1d: 3-2                  (525,312)\n",
       "├─LogmelFilterBank: 1-2                  (32,832)\n",
       "├─SpecAugmentation: 1-3                  --\n",
       "|    └─DropStripes: 2-2                  --\n",
       "|    └─DropStripes: 2-3                  --\n",
       "├─BatchNorm2d: 1-4                       128\n",
       "├─Sequential: 1-5                        --\n",
       "|    └─Sequential: 2-4                   --\n",
       "|    |    └─Conv2d: 3-3                  288\n",
       "|    |    └─AvgPool2d: 3-4               --\n",
       "|    |    └─BatchNorm2d: 3-5             64\n",
       "|    |    └─ReLU: 3-6                    --\n",
       "|    └─Sequential: 2-5                   --\n",
       "|    |    └─Conv2d: 3-7                  288\n",
       "|    |    └─AvgPool2d: 3-8               --\n",
       "|    |    └─BatchNorm2d: 3-9             64\n",
       "|    |    └─ReLU: 3-10                   --\n",
       "|    |    └─Conv2d: 3-11                 2,048\n",
       "|    |    └─BatchNorm2d: 3-12            128\n",
       "|    |    └─ReLU: 3-13                   --\n",
       "|    └─Sequential: 2-6                   --\n",
       "|    |    └─Conv2d: 3-14                 576\n",
       "|    |    └─AvgPool2d: 3-15              --\n",
       "|    |    └─BatchNorm2d: 3-16            128\n",
       "|    |    └─ReLU: 3-17                   --\n",
       "|    |    └─Conv2d: 3-18                 8,192\n",
       "|    |    └─BatchNorm2d: 3-19            256\n",
       "|    |    └─ReLU: 3-20                   --\n",
       "|    └─Sequential: 2-7                   --\n",
       "|    |    └─Conv2d: 3-21                 1,152\n",
       "|    |    └─AvgPool2d: 3-22              --\n",
       "|    |    └─BatchNorm2d: 3-23            256\n",
       "|    |    └─ReLU: 3-24                   --\n",
       "|    |    └─Conv2d: 3-25                 16,384\n",
       "|    |    └─BatchNorm2d: 3-26            256\n",
       "|    |    └─ReLU: 3-27                   --\n",
       "|    └─Sequential: 2-8                   --\n",
       "|    |    └─Conv2d: 3-28                 1,152\n",
       "|    |    └─AvgPool2d: 3-29              --\n",
       "|    |    └─BatchNorm2d: 3-30            256\n",
       "|    |    └─ReLU: 3-31                   --\n",
       "|    |    └─Conv2d: 3-32                 32,768\n",
       "|    |    └─BatchNorm2d: 3-33            512\n",
       "|    |    └─ReLU: 3-34                   --\n",
       "|    └─Sequential: 2-9                   --\n",
       "|    |    └─Conv2d: 3-35                 2,304\n",
       "|    |    └─AvgPool2d: 3-36              --\n",
       "|    |    └─BatchNorm2d: 3-37            512\n",
       "|    |    └─ReLU: 3-38                   --\n",
       "|    |    └─Conv2d: 3-39                 65,536\n",
       "|    |    └─BatchNorm2d: 3-40            512\n",
       "|    |    └─ReLU: 3-41                   --\n",
       "|    └─Sequential: 2-10                  --\n",
       "|    |    └─Conv2d: 3-42                 2,304\n",
       "|    |    └─AvgPool2d: 3-43              --\n",
       "|    |    └─BatchNorm2d: 3-44            512\n",
       "|    |    └─ReLU: 3-45                   --\n",
       "|    |    └─Conv2d: 3-46                 131,072\n",
       "|    |    └─BatchNorm2d: 3-47            1,024\n",
       "|    |    └─ReLU: 3-48                   --\n",
       "|    └─Sequential: 2-11                  --\n",
       "|    |    └─Conv2d: 3-49                 4,608\n",
       "|    |    └─AvgPool2d: 3-50              --\n",
       "|    |    └─BatchNorm2d: 3-51            1,024\n",
       "|    |    └─ReLU: 3-52                   --\n",
       "|    |    └─Conv2d: 3-53                 262,144\n",
       "|    |    └─BatchNorm2d: 3-54            1,024\n",
       "|    |    └─ReLU: 3-55                   --\n",
       "|    └─Sequential: 2-12                  --\n",
       "|    |    └─Conv2d: 3-56                 4,608\n",
       "|    |    └─AvgPool2d: 3-57              --\n",
       "|    |    └─BatchNorm2d: 3-58            1,024\n",
       "|    |    └─ReLU: 3-59                   --\n",
       "|    |    └─Conv2d: 3-60                 262,144\n",
       "|    |    └─BatchNorm2d: 3-61            1,024\n",
       "|    |    └─ReLU: 3-62                   --\n",
       "|    └─Sequential: 2-13                  --\n",
       "|    |    └─Conv2d: 3-63                 4,608\n",
       "|    |    └─AvgPool2d: 3-64              --\n",
       "|    |    └─BatchNorm2d: 3-65            1,024\n",
       "|    |    └─ReLU: 3-66                   --\n",
       "|    |    └─Conv2d: 3-67                 262,144\n",
       "|    |    └─BatchNorm2d: 3-68            1,024\n",
       "|    |    └─ReLU: 3-69                   --\n",
       "|    └─Sequential: 2-14                  --\n",
       "|    |    └─Conv2d: 3-70                 4,608\n",
       "|    |    └─AvgPool2d: 3-71              --\n",
       "|    |    └─BatchNorm2d: 3-72            1,024\n",
       "|    |    └─ReLU: 3-73                   --\n",
       "|    |    └─Conv2d: 3-74                 262,144\n",
       "|    |    └─BatchNorm2d: 3-75            1,024\n",
       "|    |    └─ReLU: 3-76                   --\n",
       "|    └─Sequential: 2-15                  --\n",
       "|    |    └─Conv2d: 3-77                 4,608\n",
       "|    |    └─AvgPool2d: 3-78              --\n",
       "|    |    └─BatchNorm2d: 3-79            1,024\n",
       "|    |    └─ReLU: 3-80                   --\n",
       "|    |    └─Conv2d: 3-81                 262,144\n",
       "|    |    └─BatchNorm2d: 3-82            1,024\n",
       "|    |    └─ReLU: 3-83                   --\n",
       "|    └─Sequential: 2-16                  --\n",
       "|    |    └─Conv2d: 3-84                 4,608\n",
       "|    |    └─AvgPool2d: 3-85              --\n",
       "|    |    └─BatchNorm2d: 3-86            1,024\n",
       "|    |    └─ReLU: 3-87                   --\n",
       "|    |    └─Conv2d: 3-88                 524,288\n",
       "|    |    └─BatchNorm2d: 3-89            2,048\n",
       "|    |    └─ReLU: 3-90                   --\n",
       "|    └─Sequential: 2-17                  --\n",
       "|    |    └─Conv2d: 3-91                 9,216\n",
       "|    |    └─AvgPool2d: 3-92              --\n",
       "|    |    └─BatchNorm2d: 3-93            2,048\n",
       "|    |    └─ReLU: 3-94                   --\n",
       "|    |    └─Conv2d: 3-95                 1,048,576\n",
       "|    |    └─BatchNorm2d: 3-96            2,048\n",
       "|    |    └─ReLU: 3-97                   --\n",
       "├─Linear: 1-6                            1,049,600\n",
       "├─Linear: 1-7                            10,250\n",
       "=================================================================\n",
       "Total params: 5,349,834\n",
       "Trainable params: 4,266,378\n",
       "Non-trainable params: 1,083,456\n",
       "================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from models import MobileNetV1, Cnn10, MobileNetV2\n",
    "from torchsummary import summary\n",
    "\n",
    "model_args = {\n",
    "      'sample_rate': 22050,\n",
    "      'window_size': 1024,\n",
    "      'hop_size': 320,\n",
    "      'mel_bins': 64,\n",
    "      'fmin': 50,\n",
    "      'fmax': 20000,\n",
    "      'classes_num': 10\n",
    "    }\n",
    "\n",
    "#model_cnn10 = Cnn10(**model_args)\n",
    "#model_cnn10.load_state_dict(torch.load('history/Cnn10_lr_0.005_ep_100_bs_64_valoss_1.49_acc_0.95_recall_0.96_precision_0.96/model_state.pt', map_location=torch.device('cpu')))\n",
    "\n",
    "mobilenetv1 = MobileNetV1(**model_args)\n",
    "mobilenetv1.load_state_dict(torch.load('history/MobileNetV1_lr_0.001_sgd_ep_150_bs_64_valoss_1.5_acc_0.95_recall_0.93_precision_0.93/model_state.pt', map_location=torch.device('cpu')))\n",
    "\n",
    "mobilenetv2 = MobileNetV2(**model_args)\n",
    "mobilenetv2.load_state_dict(torch.load('history/MobileNetV2_lr_0.001_ep_150_bs_64_valoss_1.5_acc_0.95_recall_0.93_precision_0.94/model_state.pt', map_location=torch.device('cpu')))\n",
    "\n",
    "summary(mobilenetv1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped = input_sample[:, :8820]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8820])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8820])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88200"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat1_35280.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "Converting PyTorch Frontend ==> MIL Ops: 100%|█████████▉| 343/344 [00:00<00:00, 5279.20 ops/s]\n",
      "Running MIL Common passes:   0%|          | 0/39 [00:00<?, ? passes/s]/Users/hugo/opt/anaconda3/envs/coremltools3.8/lib/python3.8/site-packages/coremltools/converters/mil/mil/passes/name_sanitization_utils.py:107: UserWarning: Input, 'input.1', of the source model, has been renamed to 'input_1' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/hugo/opt/anaconda3/envs/coremltools3.8/lib/python3.8/site-packages/coremltools/converters/mil/mil/passes/name_sanitization_utils.py:135: UserWarning: Output, '570', of the source model, has been renamed to 'var_570' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "Running MIL Common passes: 100%|██████████| 39/39 [00:00<00:00, 212.11 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 11/11 [00:00<00:00, 212.50 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 449/449 [00:00<00:00, 1148.95 ops/s]\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"history/Cnn10_lr_0.005_ep_100_bs_64_valoss_1.49_acc_0.95_recall_0.96_precision_0.96/model.pt\", map_location=torch.device('cpu'))\n",
    "dat1_7718, sampling_rate1 = librosa.load('../urbansound8k/audio/fold2/4201-3-2-0.wav')\n",
    "dat1, sampling_rate1 = librosa.load('../urbansound8k/audio/fold2/22347-3-0-0.wav')\n",
    "dat1_33957 , sampling_rate1 = librosa.load('../urbansound8k/audio/fold2/34621-4-2-0.wav')\n",
    "dat1_35280, sr = librosa.load('../urbansound8k/audio/fold6/28284-3-0-0.wav')\n",
    "\n",
    "#spplit 33957 to 8820\n",
    "\n",
    "shape_dat1 = dat1_35280.reshape(1, dat1_35280.shape[0])\n",
    "input_sample = torch.Tensor(shape_dat1)\n",
    "input_sample = input_sample[:, :35280]\n",
    "#convert_pytorch_to_coreml(cnn10, input_sample, output_filename='cnn10_96_nn_acc_{}.mlmodel'.format(input_sample.shape[1]))\n",
    "#convert_pytorch_to_coreml(mobilenetv1, input_sample, output_filename='mobilenetv1_95_8820{}.mlmodel'.format(input_sample.shape[1]))\n",
    "convert_pytorch_to_coreml(mobilenetv1, input_sample, output_filename='mobilenetv1_95_8820{}.mlmodel'.format(input_sample.shape[1]))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coremltools3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09f2296e1bd13fafdfc989bdd9574012f942b33c9bf6ca930f4e404301e975ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
