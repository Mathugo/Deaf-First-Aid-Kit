{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchlibrosa\n",
    "import numpy as np\n",
    "import onnx_coreml\n",
    "\n",
    "\n",
    "class WaveToSpectrogram(nn.Module):\n",
    "\n",
    "    def __init__( self, n_fft, hop_length, center=False ):\n",
    "        super(WaveToSpectrogram, self).__init__()\n",
    "\n",
    "        self.spec_extractor = torchlibrosa.stft.Spectrogram(\n",
    "            n_fft=n_fft,\n",
    "            hop_length=hop_length,\n",
    "            center=center,\n",
    "        )\n",
    "\n",
    "    def forward( self, x ):\n",
    "        return self.spec_extractor( x )\n",
    "    \n",
    "    def convert_to_onnx( self, filename_onnx, sample_input ):\n",
    "        input_names = [ 'input.1' ]\n",
    "        output_names = ['Spectrogram']\n",
    "\n",
    "        torch.onnx.export(\n",
    "            self,\n",
    "            torch.from_numpy( sample_input ),\n",
    "            filename_onnx,\n",
    "            input_names=input_names,\n",
    "            output_names=output_names,                     \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in waveform\n",
    "import soundfile\n",
    "waveform, samplerate = soundfile.read( '../urbansound8k/audio/fold1/101415-3-0-2.wav' )\n",
    "sample_input = waveform[:192000].astype( dtype=np.float32).reshape((1, 192000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hugo/opt/anaconda3/envs/audio/lib/python3.8/site-packages/torchlibrosa/stft.py:193: FutureWarning: Pass size=1024 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  fft_window = librosa.util.pad_center(fft_window, n_fft)\n"
     ]
    }
   ],
   "source": [
    "model = WaveToSpectrogram( n_fft=1024, hop_length=512 )\n",
    "torch.save(model, 'Hello.pt')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to Onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# instantiate model and export it\n",
    "model = WaveToSpectrogram( n_fft=1024, hop_length=512 )\n",
    "\n",
    "model.convert_to_onnx( 'wave_to_spectrogram_model.onnx', sample_input )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to Coreml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'onnx_coreml' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mlmodel \u001b[39m=\u001b[39m onnx_coreml\u001b[39m.\u001b[39mconvert(\n\u001b[1;32m      2\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mwave_to_spectrogram_model.onnx\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m     predicted_feature_name \u001b[39m=\u001b[39m [],\n\u001b[1;32m      4\u001b[0m     minimum_ios_deployment_target\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m13\u001b[39m\u001b[39m'\u001b[39m,    \n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m mlmodel\u001b[39m.\u001b[39msave( \u001b[39m'\u001b[39m\u001b[39m/wave_to_spec.mlmodel\u001b[39m\u001b[39m'\u001b[39m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'onnx_coreml' is not defined"
     ]
    }
   ],
   "source": [
    "import onnx_coreml\n",
    "\n",
    "mlmodel = onnx_coreml.convert(\n",
    "    model = 'wave_to_spectrogram_model.onnx',\n",
    "    predicted_feature_name = [],\n",
    "    minimum_ios_deployment_target='13',    \n",
    ")\n",
    "mlmodel.save( '/wave_to_spec.mlmodel' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "277706e4cc75752078803a00ba118a57c66cf643ae4eda273d9d8b4af17a45e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
